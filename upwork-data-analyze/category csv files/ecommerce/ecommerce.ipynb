{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20216256-ac78-43bf-8161-b96dafed906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b616b4b-ee47-4223-b9ba-a08b3ff61a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ecommerce.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce58779-a5be-46b7-b89f-ec56e33a2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db9abd6-0c0b-436c-bffb-4c8364c02de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jobs_type', 'title', 'jobs_text', 'URLs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21271bda-9fe3-4c38-97fc-63e98f32f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tools    63\n",
       "data     28\n",
       "leads     3\n",
       "Name: jobs_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jobs_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd504b97-a623-4430-a212-af35c505d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = df[df[\"jobs_type\"] == \"leads\"]\n",
    "tools = df[df[\"jobs_type\"] == \"tools\"]\n",
    "data = df[df[\"jobs_type\"] == \"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4dddc31-b23d-44a8-98ee-3537879cc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         1\n",
      "\"We are looking for somebody who is able to create an automated bot for eccomerce purposes which can include price tracking and (most importantly) auto checkout from price drops. \n",
      " \n",
      "At the moment, we source mid-competition products and are able to achieve this mainly with manual methods. The products are not the most competitive products out there but will still sell quite quickly. \n",
      " \n",
      "The budget for the project is just a starting point. It would be great to build a relationship with someone and to get any nessecary updates over time. \n",
      " \n",
      "It would also be great to get some professional advice on safe using of the bot (avoiding cancellations/suspensions). \n",
      " \n",
      "The right person is simply someone who knows this area and how to do the job. \n",
      " \n",
      "When applying, please mention \"purple cow\" just to show you have read this and it's not an automated copy/paste application. \n",
      " \n",
      "We can handle payment within Upwork so both parties are protected. \n",
      " \n",
      "Before starting, it would be great to discuss the project and what is involved (for example: the site in question we want to source from). \n",
      " \n",
      "Looking for a long term relationship for any releveant future projects as well. \n",
      " \n",
      "To apply, simply let me know what you think (informally) of the above and any questions. I can give more specifics. \n",
      " \n",
      "Many thanks \n",
      " \n",
      "James and Nick\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         2\n",
      "\"Hi  \n",
      " \n",
      "We are looking for an experienced Web scraping & Data Mining Expert to help with large volume product data script.  \n",
      "•\tScript must be very Fast  \n",
      "•\tScript must be able to scrap large Volumes of data \n",
      "•\tSet up script on the server and must be automated \n",
      "•\tScript must use Proxies  \n",
      "•\tPython / Beautiful Soup / Selenium / Scrapy  \n",
      " \n",
      "(link removed) \n",
      " \n",
      "Please see highlighted section in screenshots below \n",
      " \n",
      "1.\t(link removed) \n",
      "2.\t(link removed) \n",
      "3.\t(link removed) \n",
      "4.\t(link removed) \n",
      " \n",
      " \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         3\n",
      "\"Hello, \n",
      " \n",
      "I want to create a web scrapping bot that get information from a webpage and compare the price and the other criteria that I choose.  \n",
      "For exemple the bot will search in all the toys in \"target.com\" website and compare (based on the criteria chosen) . Later the products which i expect will appear in excel file with  amazon link. \n",
      " \n",
      "Let me know if you have any question. If you are eligible to do that, we will discuss further details. \n",
      " \n",
      "Thanks\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         4\n",
      "\"I want to do this job give this offer to me i will do my best\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         5\n",
      "\"I'm looking for some help in writing robust scrapers for Nordstrom. \n",
      " \n",
      "- I'm looking to scrape all products from Nordstrom US. \n",
      "- The scraper should be able to bypass each website's anti-scraping protections (if there are any). \n",
      "- The scraper should be able to be run daily (if possible, otherwise weekly is fine). If the product's price or availability changes, the changes should be updated in the database. \n",
      "- The scraper should be deployed onto EC2. AWS IAM credentials will be provided. \n",
      "- The data should be ingested into a Postgres database. The schema for the database will be provided. The credentials for the database will be provided. \n",
      "- Choice of language is ideally in TypeScript, but Python or Ruby is fine as well. \n",
      " \n",
      "Please note, if the scraper is not able to work, there will be no payment. \n",
      " \n",
      "I repeat, there is no payment if you don't successfully complete a working scraper that can work in production for at least 1 week. Do not pick this job unless you are confident that you can bypass Nordstrom's anti-scraping protections. \n",
      " \n",
      "Deliverables: \n",
      "- Running scraper in EC2 \n",
      "- Full code for the scraper, including all dependencies and instructions how to use it\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         6\n",
      "\"I need a python script (or ebay API) to scrape an ebay seller's listings. For example user:  . \n",
      " \n",
      "Seller has 635 items so there should be pagination if possible since ebay can only display 200 items at a time.  \n",
      " \n",
      "Scrape: item title, price, and quantity sold.  \n",
      " \n",
      "Output to CSV.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         7\n",
      "\"Hi there, \n",
      " \n",
      "Looking for someone who can connect our datafeed sheet of 12,000 products with our Shopify store. \n",
      " \n",
      "For each product row on the sheet, you will have to: \n",
      " \n",
      "1) Find the URL of the match  on internet and scrape the product page details. \n",
      " \n",
      "2) You will have to correctly upload all the datafeed product details (including scraped data) onto the shopify store. \n",
      " \n",
      "3) The youtube video matching the product has to be found and uploaded as well on the respective product page. \n",
      " \n",
      "As new products become available on the sheet the scraping, product upload needs to be repeated over and over again. \n",
      " \n",
      "Please note that this is a bulk automation project NOT a manual one-by-one edit and upload. \n",
      " \n",
      "In your proposal, please explain in detail what is your solution to tackling every single point mentioned above. \n",
      " \n",
      "If you do not explain your solution and timeline in detail, your proposal may get ignored and not responded. \n",
      " \n",
      "Thanks, \n",
      " \n",
      "Hani\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         8\n",
      "\"We would like a program that allows us to scrape our competitor websites. Our business is to buy used Apple products from customers. We and our competitors has a caculator on there site that shows people how much they will receive for there used Apple products. The core of this program is to scrape the prices that our competitors give to there customers. \n",
      " \n",
      "For example one of our competitors is Swappie (check screencast): I calculated a iPhone 13 Pro Max. We want to have all the different prices like this in an excel sheet (check attachments)  \n",
      " \n",
      "Our competitors are: Swappie, 123verkopen and mresell.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         9\n",
      "\"Parts of this job may require database and indexing skillset.   \n",
      "View the Comparison Tool 2022 file to see more details about this job. \n",
      " \n",
      "This job will be broken up into 3 milestones.   \n",
      " \n",
      "Milestone 1: $50 \n",
      "Write code that edits excel files and reprints the data on 2 new tabs in a vertical format instead of the horizontal way it is now. \n",
      " \n",
      "Milestone 2: $200 to $250 \n",
      "Create an app/program that finds all the outputs that are within proximity of each other and present them in a bucketed manner. \n",
      " \n",
      "Milestone 3: $250 to $450 \n",
      "Add functionality to the program created in milestone 2.  \n",
      "Make custom searches available.   \n",
      " \n",
      "I use Excel to manually perform my searches.  You can use whatever you determine is best for this job.   \n",
      "I need all three milestones complete before Wednesday, February 2nd.  If this work is beyond your skillset and/or you can't complete it by then, please don't apply.   \n",
      " \n",
      "Those who want to be considered for Milestones 2 and 3 need to download the updated Tester File(s) and look at how I perform milestone 3 manually on the results sheet.  This is the process I need automated.  Example 3 is critical in understanding my process.  \n",
      "Show your competency by creating a report for time block 61, making buckets between 23.270 and 23.320 for group 1 only..  This is a very small area of the potential full range.  Provide what you think buckets should look like for milestone 2 and 3 for the range I just mentioned.  Use a proximity of 0.003 for when a mandatory time is found.  \n",
      "Send me your results and I'll check to see if you got the right answers.  If you do, then I know I can give you the job. \n",
      " \n",
      "Here's an overview of the Grid file your program will be working with.   \n",
      "Typically, Gird files come with about 3.6 Million outputs spread out over 300 Time Blocks.  Each Time Block has about 12,000 outputs.  Each group in a Time Block has about 4,000 outputs. So when your program searches one time block, it searches each group for matches, potentially searching up to 4,000 outputs at a time.    \n",
      "When the request is to search 3 times block at once, for example, your program would be comparing 12,000 outputs per group.  \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         10\n",
      "\"I am looking for a short Python code that can bulk create/update listings using Walmart partner API (post).\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         11\n",
      "\"\n",
      "We are looking for team or expert this may be dual role \n",
      " \n",
      "1-  Python Scrapper to help us  create the automation to scrap the website they will be listing the products to Shopify  \n",
      "1-  Shopify Web Development complete the development of shopify products  \n",
      " \n",
      " \n",
      " \n",
      "Additional information  \n",
      "Scape Various products from websites \n",
      "apply the pricing rules and create in readable format for shopify \n",
      "Create the schedule automation format  \n",
      "Create the Shopify readable format  \n",
      "ensure the accuracy of data in transformation \n",
      "complete the development of shopify website  \n",
      " \n",
      " \n",
      "For consideration  you must have following  \n",
      " \n",
      "you are aware of shopify file format \n",
      "you have done web scrapping to load the products in to shopify  \n",
      " \n",
      " \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         12\n",
      "\"Need to to develop a pricing and description API for retail products scanning\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         13\n",
      "\"Scrape 7 e-commerce websites. \n",
      " \n",
      "The functionality of scrapers includes: \n",
      " \n",
      "Collection of specified information on each page (breadcrumb, description, tabular data etc.). \n",
      " \n",
      "Ability to log in and then: \n",
      "   -Ability to scrape the entire site. \n",
      "   -Ability to scrape the price of an item from a single webpage on demand. \n",
      " \n",
      "Deployment of these functionalities as a fastAPI. \n",
      " \n",
      "Code to be handed over upon completion of the above.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         14\n",
      "\"Coder to do script to import products by scraping and import into woo commerce\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         15\n",
      "\"Hey I need a programm that when somoene buys something on my shop. The program automaticly buys it on a other webshop. When the program buys it on my account on that other webshop. It will recieve an alt account (an game account) that is completly legal, you can check fot yourself later. Then the bot needs to login into the account on the website where the alt is bought and it will see what I will attach in files. (Picture of screen with purchases). Then it can do 2 things. Or copy the new account. Or Download it als .TXT. After that the login details or TXT need to be send to the customers email, from our business email. With some text then the .TXT file or the log in details. I know this is really complicated but yes. I also atatched PDF with all info.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         16\n",
      "\"You can use any language any script \n",
      "all i need is i will upload list of phone numbers in .csv or .txt file \n",
      "and download output in .csv or .txt \n",
      "and software will start looking numbers are register or not on amazon \n",
      "i need super fast without geting ip block or any delay \n",
      "SPEED IS IMPORTANT FACTOR \n",
      "you can use multiple thread or do any thing all i need is super fast \n",
      "without proxy vpn or extarnal browser running on screen \n",
      "need software \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         17\n",
      "\"Create a Website scraper for my website That takes data from another Wordpress website to ours.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         18\n",
      "\"Hii All, I am working on an opencart ecommerce website project. \n",
      "the website is based on Ayurvedic medicines under the domain name ayurvedmarket.com. \n",
      "i am from india and i need data of all medicines of all major ayurvedic companies in India(take example from : 1mg.com) \n",
      " \n",
      "i need (Multiple Images+ price(MRP and discounted price)+ description+ substitutes)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         19\n",
      "\"Our product Trolli is a Chrome extension shopping basket. When a Trolli user is (signed in and Trolli is active) is on a product page Trolli will manually scrape relevant information from the page (The product price etc) and will display this on our widget, giving the user the option to save this item (and the info) in their basket. \n",
      "We would like the automate this process, as well as automatically adding new websites to be scraped, as a user visits a new website. \n",
      "Objective: \n",
      "To scrape from a webpage - Webpage URL, Website name, Product title, Product Image, Product \n",
      "Price. \n",
      " \n",
      "Currently: \n",
      "We have a JSON file websites' with a dictionary of websites. \n",
      "We manually inspect each webpage and take the classname (and for some cases - for the image the child element) for each relevant div. \n",
      "These classnames are manually added to our JSON file which is then called when we run our extension. \n",
      " \n",
      "url: 'aliexpress.com' \n",
      "website: 'aliexpress' \n",
      "titleSelectors: ['.product-title'], \n",
      "imageSelectors: ['.image-view-magnifier-wrap img'], \n",
      "priceSelectors: ['.uniform-banner-box-price'], \n",
      " \n",
      "On each webpage we run our JS and loop through the 'websites' urls until we have a match with the current location.href \n",
      "When we have a match we have a function to getTextElement or getlmageElement by using the 'websites' selectors to querySelector the relevant information. \n",
      " \n",
      "What we want: \n",
      "When Trolli is active and a user is on any web page: \n",
      "- To recognise a product page (looking for relevant info - price etc) \n",
      "- Automatically scrape the ÜRL, website name (usually from URL), title, image and price from page. \n",
      "JSON file to be automatically updated when a previously unknown website is added with the info (above.) \n",
      "(We will then integrate this into our function for displaying and saving the info) \n",
      "(An automated testing/QA system)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         20\n",
      "\"We have a number of retail websites we wish to scrape so that we can create mock APIs to test the product we are building.  \n",
      " \n",
      "This work will involve: \n",
      " \n",
      "1. Going to the retail website (we will confirm them with you when you start).  \n",
      "2. Scraping each category of product for the name, image, pricing.  \n",
      "3. Populating this into a Google spreadsheet.  \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         21\n",
      "\"I am looking for someone to create a script to undertake insurance quotes. I can provide the inputs for each of the quotes - there will likely be 5-10 different set of inputs for different risks. \n",
      " \n",
      "I'd like to run the script on aggregator websites (which I can provide) and export the results that are returned or connect them to and display them on a wordpress site.   \n",
      " \n",
      "The frequency of this is likely to be monthly initially, so would need someone willing and able to repeat this in that timescale. But perhaps if it's possible to build this to pull in real time quotes. \n",
      " \n",
      "To be a best fit for this project you need: \n",
      " \n",
      "- Ability to communicate clearly \n",
      "- Dedication to meet project deadlines in a timely manner \n",
      "- Attention to detail \n",
      "- Willingness to sign an NDA \n",
      " \n",
      "If you are interested in this project, please reply with your prior experience. \n",
      " \n",
      "- How would you tackle this problem. \n",
      "- A list of qualifications that make you suitable.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         22\n",
      "\"Hi im Shuayb ahmed \n",
      " \n",
      "I would like a private shoplify app created for a new website that I am building,  \n",
      " \n",
      "What I want is a way to filter through other websites like, zara, H&M, Nike, primark, Footlocker, JDsports etc and more websites in the future, what products on their sites are available in store, and with that information, id like to be able to list the products that are in store on my website if that is ok, and if new products are added to the store, or no longer in the store my website is updated with that information \n",
      " \n",
      "This will only be for London region, for now \n",
      " \n",
      "I want to make it so in the future we can easily add more stores and more options if that is ok  \n",
      " \n",
      "We want to be able to change titles, and descriptions on our own website for each listing that is put on, but we want to make sure that when the availability is no longer in store then the listing is put as out of stock. \n",
      " \n",
      "We currently do this in our MVP manually by selecting the item of clothing and pressing the availability in store button and putting our postcode, so we want to automate this process using this function that is already on  these stores websites\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         23\n",
      "\"Hi, \n",
      " \n",
      "We would like to scrape some website to verify that our product are in online. \n",
      "1/ scrap a list of website \n",
      "2/ compare this data with our list \n",
      " \n",
      "2 times a week at the beginning \n",
      " \n",
      "We do not have an idea of price \n",
      "then bugdet is open, we can discuss together. Thanks\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         24\n",
      "\"We are looking for an expert on data mining, web scraping & data extraction to develop an internal tool to monitor the revenue, page view and conversion trends of products on marketplaces across the world.  \n",
      " \n",
      "We would like to get an estimate for this project.  Thanks. \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         25\n",
      "\"I've eCommerce but I've had difficulty to update my catalog. \n",
      "I'd like to create a scraping about it, but I don't have scripting knowledge and I need your help to create it. \n",
      "I don't insert the budget. About it, we can agree through email. \n",
      "Thank you so much!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         26\n",
      "\"I have already a programm which scrapes data out of Amazon and works with the Amazon API. It now needs support, due that the other programmer doesnt want to support it anymore. Its an ongoing job with monthly payment. I estimate the monthly effort to 2-3 hours. It also needs now already a little update. More information private.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         27\n",
      "\"We are looking for someone who can build a tool(scrapper/crawler) to collect data from a list of 1000 different websites as a start. \n",
      " \n",
      "If the results are positive and the data is consistent and passes spot-checking there will be more. \n",
      " \n",
      "The data we need consists of products details (category, size, price...) along with some other information mentioned on these websites. \n",
      " \n",
      "An excel template will be provided with the full data columns required. \n",
      " \n",
      "We also require an estimate on the time that this would take to \"programme\" the Scraper \n",
      "and the time it will likely take to collect the data and the software that you would use to populate the template. \n",
      "  \n",
      "Please send an offer if you able to deliver on the above.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         28\n",
      "\"Scrape this eBay data:  \n",
      " \n",
      "Using the 'title' of the eBay listing, see if products scraped from eBay match any of the products in the attached file (there are four tabs).  \n",
      " \n",
      "The end product should be our excel file with each of the four tabs being populated with a low and high price for any excel product IDs that match eBay listings in that scraped data. I would also like the scraped eBay data, to check your analysis.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         29\n",
      "\"Sir, \n",
      "We need a set of offers listings datas from Amazon pages, based on ASIN we will provide. \n",
      " \n",
      "We will need to update the informations every 2 or 3 Months. \n",
      "There will be 4 - 6 runs / year. \n",
      " \n",
      "We do not need the tool, we need the result in the form of Text / Excel / access file.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         30\n",
      "\"Find SKUs for a list of products within an inventory spreadsheet.  The list contains 400 products.  The inventory spreadsheet contains 1200 items.  Need to find the best match for each product from the spreadsheet.  \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         31\n",
      "\"We are looking for a developer with web crawling/scraping experience to write an automated process to search for product SKUs for a list of URLs.  We have a client that wants to determine which SKUs are represented on a list of locations that carry their products.  I can provide the URLs and the product SKUs.  \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         32\n",
      "\"We are looking for a developer with web crawling/scraping experience to write an automated process to search for product SKUs for a list of URLs.  We have a client that wants to determine which SKUs are represented on a list of locations that carry their products.  I can provide the URLs and the product SKUs.  \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         33\n",
      "\"We have to scrape a number of ecommerce websites. Experienced developer please apply\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         34\n",
      "\"We require the services of a professional website and product data scraper. \n",
      "Our client needs the existing product data on their website which is hosted on webflow scraped into a format for adding to their new Shopify site.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         35\n",
      "\"Hi There, \n",
      " \n",
      "I'm looking for someone with experience crawling prices from various e-commerce websites. I need a Price monitoring, comparison & repricing tool. \n",
      " \n",
      "We want to apply this for internal use only. Perhaps someone has established a platform before? We will host this server ourselves. \n",
      " \n",
      "Hope someone can help me.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         36\n",
      "\"I am looking for a Python scraper to extract prices and other data from a popular retail website.  \n",
      " \n",
      "I will provide a set of root pages and you extract all the products on the page.  \n",
      " \n",
      "Then you will save this data into an SQLite database using provided schema. \n",
      " \n",
      "Requirements: \n",
      "-Peewee or SQLAlchemy \n",
      "-asyncio or threading/queue for concurrent requests \n",
      "-Multiple proxy support \n",
      " \n",
      "This is a paid interview, if this goes well you will get more projects.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         37\n",
      "\"Need to Scrape products detail from Different E-commerce websites. \n",
      "List of websites will be provided but we have some requirements. \n",
      "If you think you are the one then First of all check our requirements and all the details of the project by Clicking at Sections on the web page given below: \n",
      "(link removed)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         38\n",
      "\"Hi, I need to move ALL old blog posts from Blog #1 on Wordpress to a new Blog #2 on Squarespace. \n",
      " \n",
      "Blog #1 is here: (link removed) \n",
      " \n",
      "You can see there are 22 pages of blog posts -- so, there seem to be roughly 100 old blog posts that I need to move over. \n",
      " \n",
      "You do not need to edit any of the posts. I only need to grab all of the old blog info and paste it over to my new blog as plain text. \n",
      " \n",
      "Ideally this could be done with a web crawler or web scraper of some kind? I am not sure. \n",
      " \n",
      "The final deliverable will be complete when all the old blog posts have been successfully moved over to the new blog.  \n",
      " \n",
      "I will share the URL for the new blog once we start to message with one another. \n",
      " \n",
      "Thank you!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         39\n",
      "\"I'm looking for someone to pull product imagery from brand websites for e-commerce product detail pages. I need clean and crisp looking product and will provide the list of UPCs to be focused on.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         40\n",
      "\"I am looking for a simple scraper built using python, asyncio and stores to an SQLite database using a specific provided database schema.  \n",
      " \n",
      "The retail site is a fast fashion retailer. The goal is to extract prices, titles and other fields from a specific section.  \n",
      " \n",
      "The end deliverable is the scraper code itself functioning as outlined above. I expect the crawler to be built in a modular and re-usable fashion. \n",
      " \n",
      "To apply please share your scraping experience. And also your knowledge of asyncio or willingness to use asyncio for this project. Thank you for your time.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         41\n",
      "\"Hi  \n",
      "We need Quotation for 2000 products Scraping. Please check Attachments. \n",
      "We require CSV/Excel Sheet in WooCommerce Format. \n",
      "Here is a Link as A demo. \n",
      " \n",
      "Thank you  \n",
      " \n",
      " \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         42\n",
      "\"We're need an integration of 3 differents files: \n",
      " \n",
      "1) The Database file \n",
      "              a) Our assitances will introduce some information from a Google Form, the most important data intruduced will be the ASIN; \n",
      "              b) On a different Tab; from these ASIN we need to fetch using the keepa api the following information: \n",
      "Image, Brand, Size, Color, Link to Amazon, Buy Box, Buy Box: 90 days avg., Buy Box: Min, Buy Box: Max and Category \n",
      "              c) We also will introduce more information, the most important there will be the \"Status\" and can be \"Approved\" or \"Denied\" \n",
      " \n",
      "2) The Second file = \"Approved\" \n",
      "This file will be a filter with a query, only \"Approved\" products from the Databes file will be displayed. \n",
      "On this file, we will introduce 2 new columns, the most important will be \"Client\" (from a list) \n",
      " \n",
      "3) The third file = \"Shopping List - Client 1 and 2\" // \"Shopping List - Client 3 and 4\"\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         43\n",
      "\"Hi there \n",
      " \n",
      "We would need someone who can help us get Data from two different websites and export it as cdv files so we can import them into our CRM system.  \n",
      " \n",
      "Kind, Bujar\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         44\n",
      "\"I am a realtor and use the multiple listing service (MLS) database to search for properties for my clients. I need an experienced developer/programmer to build a tool/program to scrape this database and export the information into a Google Sheet file. \n",
      " \n",
      "I recorded a quick video outlining the process and objectives. \n",
      " \n",
      " \n",
      " \n",
      "Feel free to respond with a realistic budget and timeline for this project. I have hired a freelancer on Upwork in the past to do a similar project so I have a rough idea of what it should take. \n",
      " \n",
      "I look forward to working with the right freelancer to complete this project! \n",
      " \n",
      "Thank you, \n",
      "Luke\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         45\n",
      "\"We're an ecommerce company that is in need of a simple Google Data Studios report to be set up and connect the following platforms for quick reading: \n",
      " \n",
      "Shopify \n",
      "Klayvio \n",
      "Marsello (shopify app) \n",
      "Facebook Business Manager \n",
      "Pinterest Business Manager \n",
      "Post Pilot (shopify app) \n",
      "Google Ads \n",
      " \n",
      "The goal is to provide the CEO with a live & up to date page to see top level numbers quickly.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         46\n",
      "\"To create a weekly procedure for scraping specific product information from a specific web shop, such as product number, title, description, material, price, etc.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         47\n",
      "\"We have 3 different B2B vendors who display catalogs for the various eyewear brands we sell. \n",
      "We would like to connect to these 3 different sites (which are not public but have login with user and password) and extract all the catalog and then upload it to woocommerce. \n",
      " \n",
      "I would prefer that the scraping of the sites is done via PHP and the credentials of the sites were managed by the Wordpress backend.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         48\n",
      "\"I am building a new woocommerce website, and I would like to scrape the productdata from an external magenta website.  I am not the owner of the external website.  \n",
      " \n",
      "The scraping might be required weekly or monthly. The data that I need is: \n",
      " \n",
      "-Product description \n",
      "-Product images \n",
      "-Product attributes \n",
      "-Stock \n",
      "-Price (increased +15%) \n",
      "etc. \n",
      " \n",
      "On the external website prices are hidden untill you login, I do have an account for that.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         49\n",
      "\"Hi, \n",
      " \n",
      "I'm working on a new project to target Shopify App Store developers and need to get the list of App Store developers into my CRM system. \n",
      " \n",
      "The directory to scrape is  \n",
      " \n",
      "I've created a spreadsheet with all of the fields that I need to scrape which can be found at:  \n",
      " \n",
      " \n",
      "The only element which might be tricky is the pricing plans as there may be a variable amount.  I've tried to outline which page elements to use to find these in the spreadsheet above. \n",
      " \n",
      "Let me know if this looks like something that could be done quickly.  I'm hoping to have this by end of the week. \n",
      " \n",
      "Thanks, \n",
      "Chris\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         50\n",
      "\"The project is about a simple portal that extracts and publishes seller ratings and products.  \n",
      " \n",
      "Reference :https://www.sellerratings.com/amazon/india/goindiaorganic-health-products \n",
      " \n",
      " \n",
      "A scraper shall be able to scrape sellers for a combination of  \n",
      " \n",
      "Amazon Region + Category \n",
      " \n",
      "and extract / interpret information as per the reference page.  \n",
      "In particular it should scrape and display \n",
      "1) reviews, ratings \n",
      "2)Selling since \n",
      "3)Brands that a seller sells \n",
      "4) Offers Prime or not \n",
      "5) Seller Rank based on the change in the number of reviews  \n",
      "6) Seller ID based contact us page - (link removed) \n",
      "7) List of all products sold by the seller with main image and product name linked to their Amazon URLs  \n",
      "8) Create list of similar sellers \n",
      "9) PHP based frontend to list all pages and country specific search as per reference link. \n",
      " \n",
      " \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         51\n",
      "\"I am building a new woocommerce website, and I would like to scrape the productdata from an external magenta website.  I am not the owner of the external website.  \n",
      " \n",
      "The scraping might be required weekly or monthly. The data that I need is: \n",
      " \n",
      "-Product description \n",
      "-Product images \n",
      "-Product attributes \n",
      "-Stock \n",
      "-Price (increased +15%) \n",
      "etc. \n",
      " \n",
      "On the external website prices are hidden untill you login, I do have an account for that.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         52\n",
      "\"We have a custom item that has loads of customization/inputs from the customer.  \n",
      " \n",
      "This app will basically become a landing page that shows customization/updates as customers are selecting them. \n",
      " \n",
      "It needs to be smooth, reactive &  should be replicated able on other stores. \n",
      " \n",
      "Further information will be shared with the right candidate.  \n",
      " \n",
      "Budget is just a benchmark and can be revisited.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         53\n",
      "\"Looking for a developer to create an amazon scraping bot, looking for someone who has had experience in automation. \n",
      " \n",
      "Start early as possible.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         54\n",
      "\"Deliverable is code to scrape ebay produces raw html and captures listing images\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         55\n",
      "\"I need a Zillow scraper capable of scraping details of around 2k rental properties each week. Rate is negotiable. To increase chances of getting an interview, please tell us about  your past experience on similar projects.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         56\n",
      "\"We are looking for an crawler and scrapper that would discover existing ecommerce websites and sort them by their major keywords, or their products. The websites we are looking at run the shopify, wix, and squarespace frameworks. Components would potentially require a crawler, a scrapper, an indexer, a ranker, and a query parser. Let us know if you are interested in work with us.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         57\n",
      "\"I am looking for someone to create a small desktop based program that uses the eBay API to retrieve all my active listings from ebay. We have in excess of 2,000,000 listings on different wordwide ebay sites. The eBay File Exchange will only download 1,000,000 at any one time. The fields we need retrieving are Item ID, Custom Label and eBay Site. The program should be able to output the result in either excel, csv or text format.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         58\n",
      "\"i own an online Vitamin Store and need 100 products, photos, descriptions and nutritional information scrapped from Amazon and imported into my Wordpress site.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         59\n",
      "\"We are looking for someone to set up a system to web scrape our supplier's website to pull the data from their products (Titles, Photos, Descriptions, Inventory Count, Etc.) and push that data into our Shopify storefront as products. We also have an entire Spreadsheet with product data (excluding product photos) \n",
      " \n",
      "The supplier's website is password protected. We obviously have an official account with them and permission to scrape the data. \n",
      " \n",
      "I can explain more in messages and provide you links to the websites to make things more clear.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         60\n",
      "\"Summary: Create a python script to get new clothing products from online stores and add to MySQL table, update existing MySQL products in table if necessary. \n",
      " \n",
      "Please see link below for detailed requirements.  \n",
      " \n",
      " \n",
      " \n",
      "Delivery: 1 python file for each store. Each python file must complete both tasks described in document.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         61\n",
      "\"Looking for a scraper to help add new product to our eyewear site. Each product has several variants that will need placed in the correct excel csv format. Products will contain different things like size and color. We can provide a sample spreadsheet.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         62\n",
      "\"We have an Excel Sheet of product codes , and a vendor website where we need to input these excel codes into the search bar, choose the product, and extract the vendor code that is showing on their side. We also would like to have the features, images, description of these products too. Please let me know if this is something that you can help with. Thanks!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                                         63\n",
      "\"Hello, \n",
      " \n",
      "I need an expert to scrap 1 million products to a new bigcommerce website, and to scrap daily price, stock. \n",
      " \n",
      "Thanks\"\n",
      "\n",
      "\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "# Jobs text\n",
    "\n",
    "count = 0\n",
    "\n",
    "jobs = list(tools[\"jobs_text\"])\n",
    "\n",
    "for job in jobs:\n",
    "    count += 1\n",
    "    print(f\"                                                         {count}\")\n",
    "    print(job)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10e24f-a619-421e-af3b-90dd1d354ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
