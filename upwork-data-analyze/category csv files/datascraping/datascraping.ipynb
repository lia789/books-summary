{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20216256-ac78-43bf-8161-b96dafed906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b616b4b-ee47-4223-b9ba-a08b3ff61a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datascraping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce58779-a5be-46b7-b89f-ec56e33a2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db9abd6-0c0b-436c-bffb-4c8364c02de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jobs_type', 'title', 'jobs_text', 'URLs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21271bda-9fe3-4c38-97fc-63e98f32f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data     140\n",
       "tools     77\n",
       "leads     18\n",
       "Name: jobs_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jobs_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd504b97-a623-4430-a212-af35c505d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = df[df[\"jobs_type\"] == \"leads\"]\n",
    "tools = df[df[\"jobs_type\"] == \"tools\"]\n",
    "data = df[df[\"jobs_type\"] == \"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4dddc31-b23d-44a8-98ee-3537879cc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            1\n",
      " Need a script to scrape and email Bizbuysell.com listings every day \n",
      "https://www.upwork.com/jobs/~01fdf1c1f97f8040ed\n",
      "\n",
      "\"Bizbuysell.com is a site where business are listed for sale. I have a premium account (please see attached screenshot), so I can see how many days the business has been listed for and how many saves it has. I would like a CSV emailed to me every day or every week with all the businesses scraped and listed on each row. It must include: \n",
      " \n",
      "- Title of the listing \n",
      "- All of the metrics in both screenshots \n",
      " \n",
      "Please quote your best price so I can have this done. Thank you!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            2\n",
      " Scraper for Google Maps. \n",
      "https://www.upwork.com/jobs/Scraper-for-Google-Maps_~01b297334fae12eb31?source=rss\n",
      "\n",
      "\"Hi! \n",
      " \n",
      "I want to create a tool to obtain data from Google Maps. \n",
      " \n",
      "The objective is to get info about organizations that are in a specific zone or neighborhood. \n",
      " \n",
      "The data that I want is: \n",
      "- Name. \n",
      "- Adress. \n",
      "- Contact info. \n",
      "- Business area (Software, Real Estate...) \n",
      " \n",
      "That data should be collected in a CSV file. \n",
      " \n",
      "It should be entirely legal, using an API from Google. \n",
      " \n",
      "Let's work together!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            3\n",
      " Need an expert in data scraping from a site protected by Mapbox API \n",
      "https://www.upwork.com/jobs/Need-expert-data-scraping-from-site-protected-Mapbox-API_~01d9ee26c706bfe267?source=rss\n",
      "\n",
      "\"Hello, \n",
      " \n",
      "We need to scrape some data similar to what is available on the website:  \n",
      " \n",
      "Scroll down to the section \"Commercial Solar Coast to Coast\", there's a US map that has small and big bubbles, which if you click you get some info. We need that info in a tabular form. I've attached a screenshot too.  \n",
      " \n",
      "Please apply only if you are 100% sure you can do it. This data is protected with an API and thus it's challenging.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            4\n",
      " PYTHON Expert for Web Scraping Job  \n",
      "https://www.upwork.com/jobs/PYTHON-Expert-for-Web-Scraping-Job_~01e07aa6a01bea3e1a?source=rss\n",
      "\n",
      "\"Hello, \n",
      "We are looking to hire an expert who knows (P.Y.T.H.O.N) for WEB scraping. \n",
      " \n",
      "I'm looking to hire an expert in extracting documents from the web. These documents may be found on websites, chatrooms, or forums. \n",
      " \n",
      "**I do not have a specific URL to provide** \n",
      " \n",
      "I only have my best guess at keyword phrases that might uncover the information either on the regular web or potential buried deep within the Web (Light or Dark). You will need the ability to search and find this without a specific website to crawl. \n",
      " \n",
      "More information in followup email. \n",
      " \n",
      "**This job is NOT for someone with only data entry experience or spreadsheet building.** \n",
      " \n",
      "Please respond if you're interested. Thank you.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            5\n",
      " Web data scraper \n",
      "https://www.upwork.com/jobs/Web-data-scraper_~0173019c51e2cbc63e?source=rss\n",
      "\n",
      "\"We are looking for a freelancer who can collect information from a site utilizing a scrapping tool. Contact us for more information.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            6\n",
      " Web Scraping Google Places API Restaurant Data for New York & Auckland \n",
      "https://www.upwork.com/jobs/Web-Scraping-Google-Places-API-Restaurant-Data-for-New-York-amp-Auckland_~01ef3215cfc5a7ce7a?source=rss\n",
      "\n",
      "\"***Looking for a developer to scrape Google Places API like a BOSS*** \n",
      " \n",
      "We are in the process of planning our expansion all over the world and are looking for an excellent web scraper to help us scrape the Google places API in cities like New York, clean and organise the data so we can perform analysis and execution.  \n",
      " \n",
      "This will need to be used:  \n",
      " \n",
      "This is an excellent opportunity for a developer to show us just how good you are at producing city scrapes in a timely manner with a clean data set.  \n",
      " \n",
      "We are planning to expand to cities all over the world and I will be looking for a superstar I can deliver. If this is the case, there will be a steady stream of data and engineering requirements from the expansion team.  \n",
      " \n",
      "The first objective will be to scrape Google Places API for New York & Auckland. I will be looking for criteria to be included like:  \n",
      " \n",
      "Reviews  \n",
      "Restaurant name \n",
      "Number of reviews \n",
      "Suburb \n",
      "City \n",
      "Cuisine  \n",
      "Lat/Long (if possible) \n",
      "Number of branches \n",
      "Price \n",
      "URL \n",
      "Contact \n",
      " \n",
      "I look forward to hearing from you if this is of interest.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            7\n",
      " Want to scrape data from website to excel sheet. \n",
      "https://www.upwork.com/jobs/Want-scrape-data-from-website-excel-sheet_~01c548e73867a4eb12?source=rss\n",
      "\n",
      "\"there is a data on some file .. i need to transfer it in excel sheet. \n",
      "will share the login details. \n",
      "data is visible on same page. \n",
      "attaching a video ..please check .\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            8\n",
      " Regular Website Scraping Projects \n",
      "https://www.upwork.com/jobs/Regular-Website-Scraping-Projects_~0127245e8388404b7a?source=rss\n",
      "\n",
      "\"I'm looking for someone who can occasionally scrape websites for structured text data like questions, jokes, and riddles and return the data to me either in a csv file or a shared Google Doc spreadsheet. \n",
      " \n",
      "Projects will require a minimum of 1,000 rows of data.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            9\n",
      " Daily data scrape of job postings from Career Websites to Google Sheets \n",
      "https://www.upwork.com/jobs/Daily-data-scrape-job-postings-from-Career-Websites-Google-Sheets-Excel_~0197040f2de1a8007e?source=rss\n",
      "\n",
      "\"I am building a database of job posts to be shared in text format on a daily basis. I need someone to scrape a number of job postings (including its descriptions) from career websites (which I will share) to be converted into a file of GSheets daily.  \n",
      " \n",
      "Keep in mind that quantity of data scraped will grow along the way, so that automated solutions/bot would be preferred. I will need to verbally describe my ideas to you, so you must have good communication skills in English. \n",
      " \n",
      "Final deliverables: \n",
      " \n",
      "GSheet/Excel file consisting of scraped job postings sent/updated to me daily.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            10\n",
      " Web-Scraping newspapers  \n",
      "https://www.upwork.com/jobs/Web-Scraping-newspapers_~01b2043f437253fb4d?source=rss\n",
      "\n",
      "\"I need to automate search in 2-3 newspapers in 6 countries (UAE,Bahrain, KSA, Oman, Qatar, Kuwait) looking for key works such as GDP, Inflation, CPI, PPI, Total Number, Average, Increase, decrease, %, Percentage, Growth, …..) all statistical key words. \n",
      "I need to have daily file (preferably Excel). Can you do it? \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            11\n",
      " Google review Datascaping \n",
      "https://www.upwork.com/jobs/Google-review-Datascaping_~01cadee64307066836?source=rss\n",
      "\n",
      "\"I want to scrap reviews from google review and send it to a google sheet as rows.  As new reviews are added, i want the data to be sent to google sheets. \n",
      " \n",
      "Name of the review \n",
      "Number of reviews the have done \n",
      "Stars given \n",
      "comment \n",
      "Date done \n",
      "Date extracted \n",
      "number of thumbs up (if possible)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            12\n",
      " App content scrapping  \n",
      "https://www.upwork.com/jobs/App-content-scrapping_~015b931aa854438632?source=rss\n",
      "\n",
      "\"I'm looking for a professional who could help me scrap data from the following apps :  \n",
      " \n",
      "1. parenting.firstcry.com \n",
      "2. babysparks -  \n",
      " \n",
      "Looking to get data/content available in all the sub urls.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            13\n",
      " Simple Scrapping Script with Rotating Proxy \n",
      "https://www.upwork.com/jobs/Simple-Scrapping-Script-with-Rotating-Proxy_~0192ea693ac440822a?source=rss\n",
      "\n",
      "\"I am looking for a simple scrapping script.  There are 200K search query I need to run to query the site result.  \n",
      " \n",
      "Then, the result should be parse and insert to DB.  \n",
      " \n",
      "The script should support varying the duration between query and also use free rotating proxy.  \n",
      "The script should be able to restart and resume from where it left off.  \n",
      " \n",
      "This script does not need to work very fast, but just work continuously ( and can resume from where it left off if restarted ) to finish the data query. \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            14\n",
      " Pulling data from website API and listing it to excel  \n",
      "https://www.upwork.com/jobs/Pulling-data-from-website-API-and-listing-excel_~015541c175fbd466e6?source=rss\n",
      "\n",
      "\"So i want to pull skin prices from cs.deals website API and list them real time to excel sheet in - game,item.price format.  \n",
      "If you need further clarification please let me know.  \n",
      "(link removed)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            15\n",
      " Web crawler required   \n",
      "https://www.upwork.com/jobs/Web-crawler-required_~01b629f0f2fb732095?source=rss\n",
      "\n",
      "\"I need someone to create a list of URL's for a specific company that I want to research. I am looking for two things.  The first is for all PDF's such as annual reports for any company that contains this companies name (to be disclosed once I have appointed a freelancer).  I also want all the URLS for the below:  Only experienced freelancers to apply please. PLEASE ADVISE HOW LONG IT WILL TAKE YOU TO COMPLETE THE PROJECT.  \n",
      " \n",
      "Adobe Portable Document Format (.pdf) \n",
      "\t•\tAdobe PostScript (.ps) \n",
      "\t•\tAutodesk Design Web Format (.dwf) \n",
      "\t•\tGoogle Earth (.kml, .kmz) \n",
      "\t•\tGPS eXchange Format (.gpx) \n",
      "\t•\tHancom Hanword (.hwp) \n",
      "\t•\tHTML (.htm, .html, other file extensions) \n",
      "\t•\tMicrosoft Excel (.xls, .xlsx) \n",
      "\t•\tMicrosoft PowerPoint (.ppt, .pptx) \n",
      "\t•\tMicrosoft Word (.doc, .docx) \n",
      "\t•\tOpenOffice presentation (.odp) \n",
      "\t•\tOpenOffice spreadsheet (.ods) \n",
      "\t•\tOpenOffice text (.odt) \n",
      "\t•\tRich Text Format (.rtf) \n",
      "\t•\tScalable Vector Graphics (.svg) \n",
      "\t•\tTeX/LaTeX (.tex) \n",
      "\t•\tText (.txt, .text, other file extensions), including source code in common\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            16\n",
      " Website Scraping \n",
      "https://www.upwork.com/jobs/Website-Scraping_~01850b715b055381c5?source=rss\n",
      "\n",
      "\"Hi there, I am looking for someone to build a scraper that will pull all the multiple choice questions off a website including questions, options, answers and explanations and put it into an excel spreadsheet. A template of which I can provided. Would like to be provided with the scraper so I can rescrape at a later stage.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            17\n",
      " Build simple code scraper for competitor keyword \n",
      "https://www.upwork.com/jobs/Build-simple-code-scraper-for-competitor-keyword_~01f964670d685cb37b?source=rss\n",
      "\n",
      "\"Please build a tool that we can use to: \n",
      "- go through a csv list of websites \n",
      "- search the source code for each one for a competitor's brand name \n",
      "- return a result with all found keywords \n",
      " \n",
      "The result should be exportable into a csv format.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            18\n",
      " Google search and web crawler  \n",
      "https://www.upwork.com/jobs/Google-search-and-web-crawler_~01889b139cf01647e8?source=rss\n",
      "\n",
      "\"I need someone to be able to enter a good search that pulls PDF documents in Australia that contain the work Employment Hero. What I am trying to achieve is I am looking for company annual reports that show they use Employment Hero which is software that businesses use to manage their workforce.  \n",
      " \n",
      "I would either take the URLs or alternatively the PDFs if that was a possibility. Please tell me how long you think the task will take you.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            19\n",
      " Use Yelp API to gather business data \n",
      "https://www.upwork.com/jobs/Use-Yelp-API-gather-business-data_~010af56047d6f6fb30?source=rss\n",
      "\n",
      "\"You will create a simple data miner using Google Sheet and the Yelp API. \n",
      " \n",
      "The mining program your create will pull data from the Yelp API and place it into a google sheet. \n",
      " \n",
      "For example, I will enter: \n",
      " \n",
      "Zip Code: 91020 \n",
      "Keyword Phrase: Mexican Restaurants \n",
      " \n",
      "The program will then run and return a list of all the Mexican Restaurants for that zip code into the spreadsheet with the following types of columns: \n",
      " \n",
      "1. Business Name \n",
      "2. Business Location \n",
      "3. Phone Number \n",
      " \n",
      "I will provide a google doc with sample data.  Actual columns returned will be different and include probably around 10+ data elements to retrieve. \n",
      " \n",
      "This should work for multiple input rows (e.g. a list of 20 zip codes). \n",
      " \n",
      "Yelp API: \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            20\n",
      " Create python script to scrape movies \n",
      "https://www.upwork.com/jobs/Create-python-script-scrape-movies_~01e5dc0152d3392725?source=rss\n",
      "\n",
      "\"Create python script to scrape movies and serials using TMDB API and save to database (MySQL)\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            21\n",
      " Need a script to download data from public web \n",
      "https://www.upwork.com/jobs/Need-script-download-data-from-public-web_~01f0eb4a5b01d98b93?source=rss\n",
      "\n",
      "\"I need help to develop a script.  \n",
      " \n",
      "This script will do the following: \n",
      "- download data from a public website. \n",
      "- publish the data to postgres db and update the count \n",
      "- upload new data to AWS s3 bucket\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            22\n",
      " Web Scraping of a website  \n",
      "https://www.upwork.com/jobs/Web-Scraping-website_~01614747d8929b9fab?source=rss\n",
      "\n",
      "\"I am looking for someone to pull US Zip codes and run a script to pull names and phone numbers from a particular website. It doesn't matter how you see it gets completed besides i would like a script to be created no manual entry work.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            23\n",
      " Quick Web Scraper needed. \n",
      "https://www.upwork.com/jobs/Quick-Web-Scraper-needed_~018d1e9d4ffe1a9b4e?source=rss\n",
      "\n",
      "\"A quick web scraper is needed to scrape this website   . \n",
      "I want the Name and Emails of all professionals whose first names start with \"A\". \n",
      " \n",
      "To do this: \n",
      "Just type \"a\" in the \"First Name\" box and scrap all the results you will get and send me the names and emails in a CSV/Excel sheet. \n",
      "Thanks.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            24\n",
      " PGA Golf Score Scraper \n",
      "https://www.upwork.com/jobs/PGA-Golf-Score-Scraper_~01fba45fc9a1c467fb?source=rss\n",
      "\n",
      "\"Hello \n",
      " \n",
      "I want a score scraper by round from pga.com - this is for completed tournaments and tournament in progress. \n",
      " \n",
      "Basically I type the pga link in like this: pgatour.com/competition/2022/the-honda-classic/leaderboard.html \n",
      "and it will grab the players scores for each round \n",
      " \n",
      "simple csv output would be great each player by row and each round score in a separate column \n",
      " \n",
      "Example Output file attached \n",
      " \n",
      "This is for Windows Desktop\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            25\n",
      " Scrape Data from the Web to excel \n",
      "https://www.upwork.com/jobs/Scrape-Data-from-the-Web-excel_~01d556f8f23f1f365d?source=rss\n",
      "\n",
      "\"I Want to extract the dividends historical data for stocks listed in the Egyptian stock exchange into an excel sheet and be able to update it automatically to compare the dividends Yoruba from consistency of dividends payments\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            26\n",
      " Scrape Popular Times on Google Map Data \n",
      "https://www.upwork.com/jobs/Scrape-Popular-Times-Google-Map-Data_~01273d246f2c276442?source=rss\n",
      "\n",
      "\"Create a Google Maps popular times data scrapers [see attachment] \n",
      " \n",
      "The Google Maps Popular Times on Google Maps Scraping must be proficient, dependable, and offer quick results with no errors. \n",
      " \n",
      "Must know how to convert data into well-structured data.   \n",
      " \n",
      "Schedule - be able to easily schedule the crawler on daily, weekly, monthly  basis so that we will get update search results.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            27\n",
      " Scrape data about chocolate  \n",
      "https://www.upwork.com/jobs/Scrape-data-about-chocolate_~019fa2d64fbc9b1a9d?source=rss\n",
      "\n",
      "\"Hi there, \n",
      " \n",
      "I'm looking to learn as much as I can about what consumers are saying about chocolate online. I'm looking for someone experienced with web scraping who can scrape data from ratings and reviews / forums / blogs about 8 chocolate brands.  \n",
      " \n",
      "When applying to this job, please let me know: \n",
      "1) What sources (Amazon reviews, Reddit blogs, etc.) you are able to scrape data from \n",
      "2) Which sources you recommend scraping from to understand what consumers like about various chocolate brands \n",
      "3) What format you can deliver the scraped data in \n",
      " \n",
      "Thanks very much for your help!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            28\n",
      " Scraping and news generation \n",
      "https://www.upwork.com/jobs/Scraping-and-news-generation_~01f76738f0e2b38445?source=rss\n",
      "\n",
      "\"Build a scrapper that will scrape: \n",
      " \n",
      " 1. news based on Linkedin profiles \n",
      "2. Scrape general company news \n",
      "3. Scrape financial news leveraging APis and other forms, including also companies 10K reports or earning calls. \n",
      "4. Scraping events in specific cities\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            29\n",
      " Data extraction from a directory website \n",
      "https://www.upwork.com/jobs/Data-extraction-from-directory-website_~016143141fdd8261f4?source=rss\n",
      "\n",
      "\"I am looking to get the entire website's directory into excel/CSV sheets. \n",
      "Is there a way to get the entire data from a website?\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            30\n",
      " Website scrape - Carwale \n",
      "https://www.upwork.com/jobs/Website-scrape-Cardekho_~01c6e5a05bd7d7ddbc?source=rss\n",
      "\n",
      "\"We want you to scrape the website   all cars data \n",
      " \n",
      "1. Give data every 3 weeks \n",
      "2. Give data 4 times \n",
      "3. Each time you give data you get $25 \n",
      "4. After 4 times data, hand over the script \n",
      " \n",
      "We are expecting the output as given in the following sheet \n",
      " \n",
      " \n",
      " \n",
      "The sheet should contain entire cars data available on the website\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            31\n",
      " Looking for a web scraper \n",
      "https://www.upwork.com/jobs/Looking-for-web-scraper_~01921fa1880c3cdbf4?source=rss\n",
      "\n",
      "\"Hey! I'm looking for a we scraper that can help me extract data from a few websites.  \n",
      " \n",
      "There're a few websites that have a database with information such as name, phone number and email address. To get that info, is necessary to enter a zip code.  \n",
      " \n",
      "I don't have a final list of zip codes of the city, but I do have a list of the range of the zip code. So, it'll be necessary to come up with each and every variation within that range. You can check the file that I uploaded here.  \n",
      " \n",
      "As soon as we have the list with the zip codes, we can start web scraping. Here's an exemple of website: (link removed) \n",
      "(translation: \"To find a Consultant enter your zip code\" and the green button \"search\") \n",
      "  \n",
      "We don't need much information to be extracted, but we are working on a tight schedule. \n",
      " \n",
      "If you are interested, let me know.  \n",
      " \n",
      "Thank you!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            32\n",
      " Extract competitor data from websites  \n",
      "https://www.upwork.com/jobs/Extract-competitor-data-from-websites_~017b9ea44c1f89d82a?source=rss\n",
      "\n",
      "\"Looking for someone to extract data from a website and load into an Excel spreadsheet.   There will also be some basic classification needed. \n",
      " \n",
      "Need to start asap.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            33\n",
      " Bing/Google Results to CSV | Data extraction \n",
      "https://www.upwork.com/jobs/Bing-Google-Results-CSV-Data-extraction_~01d527a38576e03f4f?source=rss\n",
      "\n",
      "\"I will provide a list 15 search terms that need to be searched with either Google or Bing. \n",
      " \n",
      "The delivery file should be an excel file  with all URLs of the results thrown by the search engine. I have found a Chrome Extension that can download into CSV results on page (you would need to do that on every page of the search terms) or if you know any other better way to do this, feel free to do it. \n",
      " \n",
      "What matters is that I need a file with all URLS from the search results into one file (on average every search query has around 200-300 search results). \n",
      " \n",
      "Search has to be set to English results and removing any safe search filter. I need attention to detail so If you read instructions please type \"FWL\" before your application \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            34\n",
      " Web Scraping Job \n",
      "https://www.upwork.com/jobs/Web-Scraping-Job_~014ceb49e6d0769375?source=rss\n",
      "\n",
      "\"Looking for a web scraper to use your web scraping intelligence and creativity to generate a list of companies using Twilio's services. \n",
      " \n",
      "If you are interested in this job, please describe which tools and methods you will use to generate thousands of companies that use Twilio's services. \n",
      " \n",
      "What creative ways can you think of to scrape information on the Internet to find out which companies use Twilio?  \n",
      " \n",
      "Can anyone scrape whoever has liked the Twilio page on LInkedin, Facebook, or Twitter?\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            35\n",
      " Web scraping for store locations \n",
      "https://www.upwork.com/jobs/Web-scraping-for-store-locations_~01af76006a9154ad33?source=rss\n",
      "\n",
      "\"We need a list of store locations of a specific company, including it's full addresses and geolocations. \n",
      " \n",
      "Bonus will be paid if the solution is shared and is re-usable by us.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            36\n",
      " [Urgent] Scrape Emails From Large List of Sites \n",
      "https://www.upwork.com/jobs/Urgent-Scrape-Emails-From-Large-List-Sites_~0183deaa47f02da8bf?source=rss\n",
      "\n",
      "\"I've got an urgent job where I need someone to scrape a contact email from a list of over 100,000+ sites. The sites all use the same platform.  You should check the index page and the contact page. Message for more details\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            37\n",
      " Python script for data scraping from google and DuckDuckGo \n",
      "https://www.upwork.com/jobs/Python-script-for-data-scraping-from-google-and-DuckDuckGo_~01b42af197df658d43?source=rss\n",
      "\n",
      "\"Hi bro hope u are doing good! \n",
      "let me know if you can write a code that can do web scrapping from google and duckduckgo and yahoo! \n",
      "i just need to scrap this details : \n",
      "emails \n",
      "phone numbers  \n",
      "webiste link \n",
      "thank u and have a nice day!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            38\n",
      " Scrape data from 2 websites into excel and compare \n",
      "https://www.upwork.com/jobs/Scrape-data-from-websites-into-excel-and-compare_~018faf8602a2d5e974?source=rss\n",
      "\n",
      "\"Scrape data from 2 websites (one is deep web, one not) into an excel/google doc sheet and automatically compare the 2 and highlight rows that fit specified criteria\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            39\n",
      " Web scraper, data extraction, 2 websites with images to xls \n",
      "https://www.upwork.com/jobs/Web-scraper-data-extraction-websites-with-images-xls_~010faa029438c0869e?source=rss\n",
      "\n",
      "\"We are looking for someone to create a web scraper for us. Product data including images from two different websites (regular) should be crawled and unnamed. One is freely accessible, for the other one you need login and password (is available). It can also be done with a browser addon (e.g. Web Scraper).  \n",
      "The result should be an excel sheet with the data and the images in low resolution. More details on request. \n",
      "----------------------- \n",
      "Wir suchen jemand, der uns einen web scraper erstellt. Es sollen Produktdaten inklusive Bildern von zwei unterschiedlichen Webseiten (regelmäß) gecrawled und ungenannt werden. Eine ist frei zugänglich, für die andere benötigt man Login und Passwort (ist vorhanden). Gern kann es auch mittels Browser addon (zb. Web Scraper) umgesetzt werden.  \n",
      "Das Ergebnis soll eine Exceltabelle sein, in dem die Daten stehen und die Bilder in niedriger Auflösung eingebunden sein sollen. Weitere Details auf Anfrage.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            40\n",
      " Web scrapping of data science  \n",
      "https://www.upwork.com/jobs/Web-scrapping-data-science_~0146fc8eeddef6f3f9?source=rss\n",
      "\n",
      "\"Scrape & monitor any data on the web. Download as API, CSV, or JSON. Lots of integrations. Leverage textual data in a pragmatic manner for insights by natural language processing. Textual data for alpha generation, product management, ESG integration and research\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            41\n",
      " Scrape collection from OpenSea with pricing and traits \n",
      "https://www.upwork.com/jobs/Scrape-collection-from-OpenSea-with-pricing-and-traits_~0182a38ed2e3cbb1c5?source=rss\n",
      "\n",
      "\"We're looking for someone to go scrape an entire collection of 10000 assets with their metadata (like image and traits) and pricing information.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            42\n",
      " Finder.io scraper \n",
      "https://www.upwork.com/jobs/Finder-scraper_~01bd9d57f4f745c54a?source=rss\n",
      "\n",
      "\"I have a finder.io account - premium and i have few million emails. \n",
      " \n",
      "The script should automate chrome and scrap emails from finder.io by uploading always lists with domains and downloading the emails later and write into a file. \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            43\n",
      " Data Scrap a web based App Store \n",
      "https://www.upwork.com/jobs/Data-Scrap-web-based-App-Store_~0158bc43735c05bb50?source=rss\n",
      "\n",
      "\"There is a web based online App Store with about 4,000 apps on it. I would like to scrape each app page to gather information like, price, contact info, reviews, etc and then deliver the info in an excel. There are about 25 fields per app that I'm interested in. Most apps are pretty straightforward and provide the same info so it shouldn't be too difficult to do. \n",
      " \n",
      "Ideally I want this information every month so someone who can make an automated process that gets this info for me would be the best.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            44\n",
      " Data scraping - scrap data from predefined url (Property listings from portal) \n",
      "https://www.upwork.com/jobs/Data-scraping-scrap-data-from-predefined-url-Property-listings-from-portal_~01d8a8971e6299f0ff?source=rss\n",
      "\n",
      "\"Take a url  \n",
      " \n",
      "example:  \n",
      " \n",
      "and extract al listings from all pages into xls sheet  \n",
      " \n",
      "Address \n",
      "Sold Date \n",
      "Size  \n",
      " \n",
      "Example \n",
      "Row 1  \n",
      "Column A - Suburb / Alexander (From url) \n",
      "Column B - Postcode / 3714 (from url) \n",
      "Column C - 849 skyline road Alexandra  \n",
      "Column D - 396.03 ha \n",
      "Column E - 29 May 2021  \n",
      " \n",
      "Note script should run through list id in url  \n",
      " \n",
      "\"list-2\" \n",
      " \n",
      "Script / execution instructions should be supplied so client can run the script post project / task completion \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            45\n",
      " Website scraping expert needed \n",
      "https://www.upwork.com/jobs/Website-scraping-expert-needed_~014721c7921985b00d?source=rss\n",
      "\n",
      "\"I’m looking to work with someone who can take a list of websites and scrape specific information.  \n",
      " \n",
      "I will be targeting b2b software companies  \n",
      " \n",
      "I will need info scraped that includes but is not limited to the categories below; \n",
      " \n",
      "-product description  \n",
      "-features \n",
      "-integrations  \n",
      "-pricing  \n",
      " \n",
      "The information needs to be well organized and most likely imported into airtable or Google sheets.  \n",
      " \n",
      "Please respond with an example of previous work and say “orange” in your proposal so I know you read this\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            46\n",
      " Write program to scrap data on a monthly basis. \n",
      "https://www.upwork.com/jobs/Write-program-scrap-data-monthly-basis_~01c4d8a27f9cd8e1ae?source=rss\n",
      "\n",
      "\"I have a web site that gets annoyed if you hit it too often. I want a tool that can scrap data from it on a monthly basis. \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            47\n",
      " Scripts for Scraping Emails and Google Sheets + Triggering WebForms \n",
      "https://www.upwork.com/jobs/Scripts-for-Scraping-Emails-and-Google-Sheets-Triggering-WebForms_~01958f034b3cfbbd06?source=rss\n",
      "\n",
      "\"Hello, \n",
      " \n",
      "We're looking for someone to create a script that will scrape specific email requests we receive (for requests for property viewings) + also a Google sheet where the emails are entered manually via phone calls we receive.   \n",
      " \n",
      "The script would then trigger off a web form we use (which is directly linked to Aweber).  I have a video which explains the process we're looking to achieve in more detail. \n",
      " \n",
      "Thanks, \n",
      "Ruban\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            48\n",
      " Scrape information from html/.eml (Email) - Python Script \n",
      "https://www.upwork.com/jobs/Scrape-information-from-html-eml-Email-Python-Script_~018b1fb6f346e09bd6?source=rss\n",
      "\n",
      "\"I need to have information from emails extracted with a python script. \n",
      " \n",
      "I will require for each block: \n",
      "- headline \n",
      "- link (from headline) \n",
      "- text \n",
      " \n",
      "There are two categories of emails: \n",
      "1. (example Deepmind AI...) - normal mail \n",
      "2. (example coinbase ...) - crypto mail \n",
      " \n",
      "when accepting the contract I will provide 20 samples each \n",
      " \n",
      "See the attached allMsgs.json file, which contains emailsnr : HTMLTEXT format. this will be how you will get access to the emails. see the .eml files for examples.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            49\n",
      " Crawl the web and download pdf's matching a search term \n",
      "https://www.upwork.com/jobs/Crawl-the-web-and-download-pdf-matching-search-term_~012785efeb8f349f06?source=rss\n",
      "\n",
      "\"I would like to search the internet for a specific search term (it is not a common search term) and download all pdf files that match the search term. \n",
      " \n",
      "Ideally it would be an executable, so I could use it for different search terms.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            50\n",
      " Scrape data from car parts website \n",
      "https://www.upwork.com/jobs/Scrape-data-from-car-parts-website_~010ca498e63bfd9fea?source=rss\n",
      "\n",
      "\"I need someone to write a script and scrape data from this website: \n",
      "sylvania-automotive.com \n",
      " \n",
      "Specifically the following fields from the \"Find your bulb\" search \n",
      "Year, make, model, location, position \n",
      " \n",
      "And the name of each resulting product. \n",
      " \n",
      "I will only be needing the 'type' in the product name which appears after the word 'SYLVANIA' \n",
      "For example, this product: \n",
      "SYLVANIA H11 LED Fog & Powersports Bulb, 2 Pack \n",
      " \n",
      "The type is 'H11' \n",
      " \n",
      "Output for all this data should be both CSV and JSON files by year which I can explain later. \n",
      "See an example of a year for the JSON files (taken from the current website mentioned below) \n",
      " \n",
      "Ultimately the data will be used in the 'Select your vehicle' for this website: \n",
      "hidnation.com \n",
      " \n",
      "Respond with the word 'green' so I know you are real\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            51\n",
      " ERA5 weather data \n",
      "https://www.upwork.com/jobs/ERA5-weather-data_~0169e601c683880b56?source=rss\n",
      "\n",
      "\"I would like to extract daily temperature/precipitation data for a number of countries (shapefile will be provided) from ERA5: (link removed) \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            52\n",
      " Scrape a simple website \n",
      "https://www.upwork.com/jobs/Scrape-simple-website_~01eaf86e04e67abace?source=rss\n",
      "\n",
      "\"I need someone to create a copy of a language learning website. It’s a list of articles with audio. There might be software that does that without any user intervention. The website is newsinslowfrench. I will give you the user name and password.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            53\n",
      " Looking for a web scraping programmers \n",
      "https://www.upwork.com/jobs/Looking-for-web-scraping-programmers_~017860c0bb9ca9e03d?source=rss\n",
      "\n",
      "\"I’m working on a research project (academia) in economics. I have a list individuals, and there is a website that includes all their working papers. I need to download the list of working papers and match them to the individuals.   \n",
      "In general, the project will include web scraping (collecting specific information from a website, downloading it, and then organizing the data to merge it to our researcher's data). \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            54\n",
      " Python  and web scraping  \n",
      "https://www.upwork.com/jobs/Python-and-web-scraping_~01919e402ccde07c1b?source=rss\n",
      "\n",
      "\"looking for a junior Python resource who can help me to scrap the data and later on download the data into database tables. total work 40-60 hours.  \n",
      "the work will be done in 2 steps. First, write the scripts and test them. secondly, create a  crown job and make sure the data is downloaded in database \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            55\n",
      " Scrapping websites to get data \n",
      "https://www.upwork.com/jobs/Scrapping-websites-get-data_~0161314f848852356c?source=rss\n",
      "\n",
      "\"I want to scrape a few websites, extract the data and give us large data dumps. Also as a next step want to automate this so that we can have this data regularly. What we are scraping for in crypto related so some crypto experience goes a long way\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            56\n",
      " Scraping Crypto Data (Prices) \n",
      "https://www.upwork.com/jobs/Scraping-Crypto-Data-Prices_~01df50fd00031368e6?source=rss\n",
      "\n",
      "\"Hi, \n",
      " \n",
      "I would like for someone to write a code to automatically harvest and show data for crypto currency prices (c. 1,500 different coins). \n",
      " \n",
      "Kindy let me know of your interest sot that we could schedule a call to discuss further. \n",
      " \n",
      "Many Thanks,\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            57\n",
      " Scraper needed to analyse hotel reviews \n",
      "https://www.upwork.com/jobs/Scraper-needed-analyse-hotel-reviews_~0198b0d73fc34464fc?source=rss\n",
      "\n",
      "\"Scraper/online researcher needed to scrape defined aspects of hotel reviews on TripAdvisor. \n",
      " \n",
      "We're looking to understand how well tourists sleep, identifying the hotels, brands, and locations where people sleep - based on the Sleep Quality score given by reviewers on TripAdvisor. \n",
      " \n",
      "To collate these, we're looking for an experienced scraper to collate the sleep quality score data from the latest 1,000 reviews for each hotel (where applicable). \n",
      " \n",
      "London ($100) is the first city we would want hotel reviews to be collated from. Should this data prove feasible and allow us to move the overall project further, we would then look to run the same script for another 49 cities ($200) - primarily in the UK, EU, and the US. \n",
      " \n",
      "As a guide the deliverables required for this project will be: \n",
      "- Scraped data of \"quality of sleep\" scores from the latest reviews of hotels in each city (max 1,000 reviews per hotel) \n",
      "- Easy to access and analyse pivots (excel) of scraped data, as well as raw sheets of data for reference. \n",
      " \n",
      "Please do get in touch if you would be able to scrape (and pivot) this data for us. \n",
      " \n",
      "Thanks so much,\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            58\n",
      " Web Scraping Expert for startup \n",
      "https://www.upwork.com/jobs/Web-Scraping-Expert-for-startup_~01224ff086724555d6?source=rss\n",
      "\n",
      "\"I'm a CTO of a startup where we would need to extract contact details of the key persons from 300k-500k websites.  \n",
      " \n",
      "Ideal outcome would be a JSON of all persons with their job titles, emails and phone numbers mentioned on the website.  \n",
      " \n",
      "Ideally the applicant would have experience of this specific problem. If you are able to describe such a case on your application, that would greatly improve your chances to be considered for the project.  \n",
      " \n",
      "If the co-operation is fruitful, we would be happy to expand the relationship and would have additional data extraction/scraping problems to work in. Thank you for your consideratione and hope to hear from You soon!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            59\n",
      " Scrape Data from App \n",
      "https://www.upwork.com/jobs/Scrape-Data-from-App_~01f569b41e40f885c6?source=rss\n",
      "\n",
      "\"I would like to scrape the data from an application. The application is behind a login.  \n",
      " \n",
      "I would like to get the full name / job title / company and tags for each of the profiles in the application.  \n",
      " \n",
      "Once we have collected all these pieces of information. I would like to run an automated script to see if we can match the names with a LinkedIn or Facebook profile.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            60\n",
      " Electricity price scraper written in python.  \n",
      "https://www.upwork.com/jobs/Electricity-price-scraper-written-python_~01db478a6d54225afe?source=rss\n",
      "\n",
      "\"I need a visual chart that displays current electricity price pulled by this api called nordpol. And overlayed with current average temperature. You will deliver source code and setup on github and you can chose method of visual presentation. Or even which python library to use. Pandas, numpy, etc  \n",
      " \n",
      "Source api here  \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            61\n",
      " Data scraper for ekstraklasa org website \n",
      "https://www.upwork.com/jobs/Data-scraper-for-ekstraklasa-org-website_~012b8fbd6eeb371b59?source=rss\n",
      "\n",
      "\"I need a scraper for data from  . \n",
      " \n",
      "Players data from each match details across the season. It must work for upcoming matches as well.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            62\n",
      " Create a web scraper that can collect and convert data from 20 different websites \n",
      "https://www.upwork.com/jobs/Create-web-scraper-that-can-collect-and-convert-data-from-different-websites_~0132745e2440bcc3e4?source=rss\n",
      "\n",
      "\"i have an existing scraper collecting data from 20 different sites. The data are collected from online search in databases and in published pdf reports. \n",
      " \n",
      "I need the scraper to be able to convert the collected data into a specific CSV format\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            63\n",
      " Website scraping needed to pull data \n",
      "https://www.upwork.com/jobs/Website-scraping-needed-pull-data_~01039d2a09a0949d24?source=rss\n",
      "\n",
      "\"Need quick but clean solution \n",
      "Need to pull publicly available data from following two websites: \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Need this data in next 2 days. Will also need the code written to execute this.  \n",
      " \n",
      "Inputs I will provide: set of pin codes/zip codes and the output fields needed to be extracted. \n",
      "\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            64\n",
      " Write a python parser to extract data from HTML and write into a Google Sheet \n",
      "https://www.upwork.com/jobs/Write-python-parser-extract-data-from-HTML-and-write-into-Google-Sheet_~017f5378110c9e4337?source=rss\n",
      "\n",
      "\"I am currently manually copy/pasting values from a website into a Google Sheet. I need someone to automate the process by writing a parser in python which finds values based on business rules and writes into a Google Sheet\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            65\n",
      " Web Scraping Software - Data Extraction Program Needed \n",
      "https://www.upwork.com/jobs/Web-Scraping-Software-Data-Extraction-Program-Needed_~016b2d932eb18b0a90?source=rss\n",
      "\n",
      "\"To create software with an interface that can do the following:  \n",
      " \n",
      "A - scrape the search results of some websites that have different searching filters. \n",
      " \n",
      "B - I need the software to allow me to choose which search filters I want it to search and scrape. \n",
      " \n",
      "C - then the software should allow me to export the scrape results to an excel/csv file. \n",
      " \n",
      "More details can be provided to the right applicant. \n",
      " \n",
      "Feel free to place your bid for this job and I will consider, thank you!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            66\n",
      " Data scraping tool  \n",
      "https://www.upwork.com/jobs/Data-scraping-tool_~015413564e8ffaac8f?source=rss\n",
      "\n",
      "\"Web Harvy Or any other scraping tool. \n",
      "I am looking to work with someone that can build me a simple web scraping tool to pull B2C listings from 3 different websites into a readable format (ideally a Google Sheet, CSV or Excel). \n",
      " \n",
      "I am looking to scrap Thatsthem.com majorly. \n",
      "The file attached will show the information that should be pulled from each website and compiled into a singular sheet. I am only interested in listings in USA. \n",
      " \n",
      "Once reviewed, please provide your cost and timeline and confirmation you have built something similar before. \n",
      " \n",
      "Thank you very much!!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            67\n",
      " Using Semrush API to scrap data \n",
      "https://www.upwork.com/jobs/Using-Semrush-API-scrap-data_~0176dd462e4a224b55?source=rss\n",
      "\n",
      "\"I want to use the Semrush API (https://www.semrush.com/kb/5-api) to pull information for approximately 1500 organizations. I will provide the name and the website links of the organization. Of course, I will also pay for the Semrush API.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            68\n",
      " Mobile app data scraping \n",
      "https://www.upwork.com/jobs/Mobile-app-data-scraping_~0147d0c7f6c43f8b01?source=rss\n",
      "\n",
      "\"Would you be able to develop a script or software for scraping data from Android/IOS apps? \n",
      " \n",
      "You can use the android or iOS app for scraping and any programming language/software, although python and JS are preferred. \n",
      " \n",
      "We will provide all other details upon request - please do not hesitate to ask any questions you may have. Thank you!\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            69\n",
      " Web scraping usernames \n",
      "https://www.upwork.com/jobs/Web-scraping-usernames_~01a52c49344db7349d?source=rss\n",
      "\n",
      "\"Hi, \n",
      " \n",
      "We would like to extract from Opensea.com accounts, their associated twitter and instagram accounts. \n",
      " \n",
      "Opensea.com allows NFT investors to create profiles, like this: \n",
      " \n",
      " \n",
      "As you can see in this profile, there are twitter and instagram accounts linked. Not all profiles have linked their twitter and instagram accounts yet, but many have. \n",
      " \n",
      "We want to create a way to extract this information and put into a CSV file with all possible twitter and instagram usernames that can be found on opensea.com. \n",
      " \n",
      "Let me know how long it would take to develop and how much would it cost please. \n",
      " \n",
      "Thanks\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            70\n",
      " Python - scrape spotify \n",
      "https://www.upwork.com/jobs/Python-scrape-spotify_~011cf96d999f788d52?source=rss\n",
      "\n",
      "\"We need to scrape spotify to get artist details to store name of artist, phone and email and number of followers \n",
      " \n",
      "So we would like to be able to input a search term e.g \"sweden\" \n",
      " \n",
      "It should then loop through all the artists.  \n",
      "- store name of artist \n",
      "In the about section there are links to facebook, instagram and website \n",
      "- navigate to facebook and instagram and see if theres an email and telephone number \n",
      "- navigate to website and see if there's a phone or email (we have a script for this that you can incorporate) \n",
      " \n",
      "It should log each artist searched and whether it found any contact details.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            71\n",
      " Solution required to get information from thousands of searches  \n",
      "https://www.upwork.com/jobs/Solution-required-get-information-from-thousands-searches_~010df04a582fc6e037?source=rss\n",
      "\n",
      "\"We are a small team of professionals based in UK, US, Luxembourg and Poland specializing in insurance, reinsurance and asset management. The scope is fairly broad and we appreciate people who also have their own ideas to share while keeping in mind the end product to achieve. We are looking for someone to help with compiling a comprehensive list of mortgage related information (~ around 1m) in Poland and using that information extract the details from publicly available searches.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            72\n",
      " Need a help with web scraping  \n",
      "https://www.upwork.com/jobs/Need-help-with-web-scraping_~0190f077910f5d2bb9?source=rss\n",
      "\n",
      "\"I need to scrape a specific information from a specific website. And this needs to be done daily. Contact me for more information.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            73\n",
      " Web Scraper Required to Read Data from Public Website \n",
      "https://www.upwork.com/jobs/Web-Scraper-Required-Read-Data-from-Public-Website_~01faa95055e897ecf6?source=rss\n",
      "\n",
      "\"Require help building a Web Scraper to parse data from the following site: \n",
      " \n",
      " \n",
      "This will be done for a large series of Team IDs.  The task will be to access the game history for each team ID and then build a complete profile for each team including their entire game history as well as additional available details about the team.  Data will be stored in a CSV, or Database for access to apply algorithms to the back-end data.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            74\n",
      " Octoparse scrape template need \n",
      "https://www.upwork.com/jobs/Octoparse-scrape-template-need_~011edae674b76371f7?source=rss\n",
      "\n",
      "\"If you have experience using Octoparse to scrape websites, then I would need your help creating a scraper to scrape this particular page \"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            75\n",
      " Website Scraper for quiz websites \n",
      "https://www.upwork.com/jobs/Website-Scraper-for-quiz-websites_~0193ed72f5a5334aae?source=rss\n",
      "\n",
      "\"Hi, \n",
      " \n",
      "I would like a website scraper built to scrape questions, options and explanations from quizzes to an excel spreadsheet. This must be built in a way that I may run this in the future on further exams.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            76\n",
      " Need Data scrapper \n",
      "https://www.upwork.com/jobs/Need-Data-scrapper_~01d3709cb73ec324ff?source=rss\n",
      "\n",
      "\"\n",
      "We're looking for an experienced freelancer, that can help us to create a script for scraping an entire website's information about stores. \n",
      "I need someone to create a script to scrap all information about stores from a certain website \n",
      "Hands on experience creating and executing various scripts for data extraction. \n",
      "Must Visit Job/Careers Page and Read Carefully detailed Job Description. \n",
      " \n",
      "Click at job description section.\"\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "                                            77\n",
      " DATA SCRAPING (2 platforms, google search) \n",
      "https://www.upwork.com/jobs/DATA-SCRAPING-platforms-google-search_~0161887561ef4b60c0?source=rss\n",
      "\n",
      "\"I need to get: \n",
      "- hotel_name \n",
      "- hotel_location \n",
      "from URLs like:  \n",
      " \n",
      "Data should be scraped from 53 URLs similar to the above and return a total of 2,667 hotel items eligible to get extracted.  \n",
      " \n",
      "When the list of 2,667 hotel is ready (name, location), then I need to query on Google: \n",
      " \n",
      "- $hotel_name $hotel_location facebook \n",
      " \n",
      "This will return the hotel facebook page on top of Google search results. \n",
      " \n",
      "Then I need the script to open the hotel facebook page and get the following contact detaills for each of the 2,667 hotels: \n",
      " \n",
      "- email \n",
      "- phone \n",
      "- website \n",
      "- address\"\n",
      "\n",
      "\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "# Jobs text\n",
    "\n",
    "count = 0\n",
    "\n",
    "jobs = list(tools[\"jobs_text\"])\n",
    "urls = list(tools[\"URLs\"])\n",
    "titles = list(tools[\"title\"])\n",
    "\n",
    "for url, title, job in zip(urls, titles, jobs):\n",
    "    count += 1\n",
    "    print(f\"                                            {count}\")\n",
    "    print(title)\n",
    "    print(url)\n",
    "    print()\n",
    "    print(job)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83b50b-8f18-4c9d-9c61-e916cfd92265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
